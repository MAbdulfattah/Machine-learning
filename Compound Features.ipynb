{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "confident-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "\n",
    "# Model Specific imports\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "helpful-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following if autocompletion is not working\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "turkish-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS:\n",
    "train_on_clean = True # Change to get the other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "stupid-plate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported train_clean.csv\n"
     ]
    }
   ],
   "source": [
    "file_name = 'train_clean.csv'\n",
    "if not train_on_clean:\n",
    "    file_name = 'train.csv'\n",
    "\n",
    "df = pd.read_csv(file_name)\n",
    "df = df[df.text.notnull()]\n",
    "df = df[df.keyword.notnull()]\n",
    "print(f'Imported {file_name}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "statutory-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import vader\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# nltk.download('vader_lexicon') ## this only needs to be run once\n",
    "\n",
    "vader_model = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "stock-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiments for text\n",
    "df['text_compound'] = df['text'].apply(lambda x:vader_model.polarity_scores(x)['compound'])\n",
    "\n",
    "# Sentiments for keyword\n",
    "df['keyword_compound'] = df['keyword'].apply(lambda x:vader_model.polarity_scores(f\"We have {x}\")['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "intimate-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_prod = lambda x: (x.text_compound * x.keyword_compound if \n",
    "    np.logical_and(x.text_compound!=0, x.keyword_compound!=0) else \n",
    "    min(x.text_compound, x.keyword_compound))\n",
    "\n",
    "df['features_compound'] = df.apply(features_prod, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "bright-nursery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>compound</th>\n",
       "      <th>text_compound</th>\n",
       "      <th>keyword_compound</th>\n",
       "      <th>features_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>bleeding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cute dinner date til cam nose start bleed</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3570</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>bloody</td>\n",
       "      <td>Adelaide, South Australia</td>\n",
       "      <td>bloody sexy drool</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>-0.4404</td>\n",
       "      <td>-0.056371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5647</th>\n",
       "      <td>suicide%20bomber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>talk risk suicide bomber hiding migrant stow a...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.8720</td>\n",
       "      <td>-0.8271</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.827100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>famine</td>\n",
       "      <td>Kyiv, Ukraine</td>\n",
       "      <td>russia food crematoria provoke outrage country...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.8519</td>\n",
       "      <td>-0.8519</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.851900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>deluge</td>\n",
       "      <td>Australia</td>\n",
       "      <td>wa smile july deluge west australian</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>blight</td>\n",
       "      <td>Daruka (near Tamworth) NSW</td>\n",
       "      <td>load welfare love sponge blight society</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>smoke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>smoke blunt amp ciggs</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>annihilation</td>\n",
       "      <td>Republic of Texas</td>\n",
       "      <td>annihilation jeb christie amp kasich hour away...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>blood</td>\n",
       "      <td>???????, ??'??????</td>\n",
       "      <td>blood group ve associate gastric carcinoma say...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4477</th>\n",
       "      <td>mudslide</td>\n",
       "      <td>Wales</td>\n",
       "      <td>hope dorett mudslide cake win gbbo</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>0.7717</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6693 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               keyword                    location  \\\n",
       "596           bleeding                         NaN   \n",
       "767             bloody   Adelaide, South Australia   \n",
       "5647  suicide%20bomber                         NaN   \n",
       "3179            famine               Kyiv, Ukraine   \n",
       "1978            deluge                   Australia   \n",
       "...                ...                         ...   \n",
       "653             blight  Daruka (near Tamworth) NSW   \n",
       "5471             smoke                         NaN   \n",
       "199       annihilation           Republic of Texas   \n",
       "720              blood          ???????, ??'??????   \n",
       "4477          mudslide                       Wales   \n",
       "\n",
       "                                                   text  target  compound  \\\n",
       "596           cute dinner date til cam nose start bleed       0   -0.3570   \n",
       "767                                   bloody sexy drool       0    0.1280   \n",
       "5647  talk risk suicide bomber hiding migrant stow a...       1   -0.8720   \n",
       "3179  russia food crematoria provoke outrage country...       1   -0.8519   \n",
       "1978               wa smile july deluge west australian       0    0.4767   \n",
       "...                                                 ...     ...       ...   \n",
       "653             load welfare love sponge blight society       0    0.5994   \n",
       "5471                              smoke blunt amp ciggs       0   -0.2960   \n",
       "199   annihilation jeb christie amp kasich hour away...       0    0.6486   \n",
       "720   blood group ve associate gastric carcinoma say...       0    0.0000   \n",
       "4477                 hope dorett mudslide cake win gbbo       0    0.7882   \n",
       "\n",
       "      text_compound  keyword_compound  features_compound  \n",
       "596          0.4588            0.0000           0.000000  \n",
       "767          0.1280           -0.4404          -0.056371  \n",
       "5647        -0.8271            0.0000          -0.827100  \n",
       "3179        -0.8519            0.0000          -0.851900  \n",
       "1978         0.3612            0.0000           0.000000  \n",
       "...             ...               ...                ...  \n",
       "653          0.6369            0.0000           0.000000  \n",
       "5471         0.0000            0.0000           0.000000  \n",
       "199          0.4588            0.0000           0.000000  \n",
       "720          0.0000            0.0000           0.000000  \n",
       "4477         0.7717            0.0000           0.000000  \n",
       "\n",
       "[6693 rows x 8 columns]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "rational-details",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_compound = df['compound'].apply(lambda x: 0 if x >= 0 else 1).values.reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_compound, df['target'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "immune-harbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5713218820014937\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "print(metrics.accuracy_score(y_test, prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "concerned-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_compound = df['features_compound'].apply(lambda x: 0 if x >= 0 else 1).values.reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_compound, df['target'], test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "coupled-chapter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6075429424943988\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "print(metrics.accuracy_score(y_test, prediction))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
